{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message(content='为什么鱼不能开车？\\n因为它们没有驾照！哈哈哈哈哈ha~', role='assistant')\n"
     ]
    }
   ],
   "source": [
    "import litellm\n",
    "import os\n",
    "\n",
    "response = litellm.completion(\n",
    "    model=\"openai/gpt-3.5-turbo\",               # add `openai/` prefix to model so litellm knows to route to OpenAI\"\n",
    "    api_key=\"sk-uwQpxn5Fa58Lkzqu00Fd1e30491f487bB867F52c043c41B9\",                  # api key to your openai compatible endpoint\n",
    "    api_base=\"https://burn.hair/v1\",     # set API Base of your Custom OpenAI Endpoint\n",
    "    messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"讲一个冷笑话\",\n",
    "                }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This\n",
      " is\n",
      " a\n",
      " test\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = litellm.completion(\n",
    "    api_key=\"sk-uwQpxn5Fa58Lkzqu00Fd1e30491f487bB867F52c043c41B9\",                  # api key to your openai compatible endpoint\n",
    "    api_base=\"https://burn.hair/v1\",     # set API Base of your Custom OpenAI Endpoint\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say this is a test\"}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for part in response:\n",
    "    print(part.choices[0].delta.content or \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name):\n",
    "    return \"Diao hai\" + name + \"!\"\n",
    "\n",
    "demo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'HttpxBinaryResponseContent' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-uwQpxn5Fa58Lkzqu00Fd1e30491f487bB867F52c043c41B9\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      7\u001b[0m speech_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech.mp3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m response \u001b[38;5;241m=\u001b[39m speech(\n\u001b[1;32m      9\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai/tts-1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m         voice\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malloy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 11\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtext,\n\u001b[1;32m     12\u001b[0m         api_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msk-uwQpxn5Fa58Lkzqu00Fd1e30491f487bB867F52c043c41B9\u001b[39m\u001b[38;5;124m\"\u001b[39m,                  \u001b[38;5;66;03m# api key to your openai compatible endpoint\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         api_base\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://burn.hair/v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,     \u001b[38;5;66;03m# set API Base of your Custom OpenAI Endpoint\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         organization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m         project\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m         max_retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     17\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m,\n\u001b[1;32m     18\u001b[0m         client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m         optional_params\u001b[38;5;241m=\u001b[39m{},\n\u001b[1;32m     20\u001b[0m     )\n\u001b[1;32m     21\u001b[0m response\u001b[38;5;241m.\u001b[39mstream_to_file(speech_file_path)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'HttpxBinaryResponseContent' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from litellm import speech\n",
    "import os \n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-uwQpxn5Fa58Lkzqu00Fd1e30491f487bB867F52c043c41B9\"\n",
    "\n",
    "speech_file_path = \"speech.mp3\"\n",
    "response = speech(\n",
    "        model=\"openai/tts-1\",\n",
    "        voice=\"alloy\",\n",
    "        input=\"the quick brown fox jumped over the lazy dogs\",\n",
    "        api_key=\"sk-uwQpxn5Fa58Lkzqu00Fd1e30491f487bB867F52c043c41B9\",                  # api key to your openai compatible endpoint\n",
    "        api_base=\"https://burn.hair/v1\",     # set API Base of your Custom OpenAI Endpoint\n",
    "        organization=None,\n",
    "        project=None,\n",
    "        max_retries=1,\n",
    "        timeout=600,\n",
    "        client=None,\n",
    "        optional_params={},\n",
    "    )\n",
    "response.stream_to_file(speech_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请求失败，状态码: 503\n",
      "响应内容: {'error': {'message': '当前分组 default 下对于模型 tts-az-1 无可用渠道 (request id: 202406131159296100354065xJKxFBg)', 'type': 'one_api_error'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# API URL\n",
    "url = 'https://burn.hair/v1/audio/speech'\n",
    "\n",
    "# 请求头\n",
    "headers = {\n",
    "    'Authorization': 'sk-uwQpxn5Fa58Lkzqu00Fd1e30491f487bB867F52c043c41B9',\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "# 请求体\n",
    "data = {\n",
    "    \"model\": \"tts-az-1\",\n",
    "    \"input\": \"Hello world\",\n",
    "    \"voice\": \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "}\n",
    "\n",
    "# 发起 POST 请求\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "# 检查请求是否成功\n",
    "if response.status_code == 200:\n",
    "    # 将返回的音频文件保存\n",
    "    with open('output_audio.mp3', 'wb') as audio_file:\n",
    "        audio_file.write(response.content)\n",
    "    print(\"音频文件已成功保存为 output_audio.mp3\")\n",
    "else:\n",
    "    print(f\"请求失败，状态码: {response.status_code}\")\n",
    "    print(\"响应内容:\", response.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
